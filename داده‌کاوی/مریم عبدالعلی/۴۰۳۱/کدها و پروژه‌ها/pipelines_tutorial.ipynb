{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines in scikit-learn are a powerful tool that can help streamline your machine learning workflows, reduce the risk of data leakage, and simplify the process of hyperparameter tuning. By chaining together data preprocessing and model training steps, you can ensure that your workflow is consistent, modular, and easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful functions\n",
    "\n",
    "- **dataframe's select_dtypes**: The select_dtypes function in pandas is used to select columns in a DataFrame based on their data types. This function is especially useful when you want to apply specific operations or transformations to columns of certain types, like numerical, categorical, or boolean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numeric_1  numeric_2\n",
      "0          1        4.5\n",
      "1          2        5.6\n",
      "2          3        6.7\n",
      "  category\n",
      "0        A\n",
      "1        B\n",
      "2        C\n",
      "   boolean_1  boolean_2\n",
      "0       True      False\n",
      "1      False      False\n",
      "2       True       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'numeric_1': [1, 2, 3],\n",
    "    'numeric_2': [4.5, 5.6, 6.7],\n",
    "    'category': ['A', 'B', 'C'],\n",
    "    'boolean_1': [True, False, True],\n",
    "    'boolean_2': [False, False, True]\n",
    "})\n",
    "\n",
    "numeric_df = df.select_dtypes(include=[int, float])\n",
    "print(numeric_df)\n",
    "\n",
    "categorical_df = df.select_dtypes(include=object)\n",
    "print(categorical_df)\n",
    "\n",
    "binary_df = df.select_dtypes(include=bool)\n",
    "print(binary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  Basic Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pipeline for Numerical Data Only\n",
    "For datasets with only numerical values, we can use a pipeline to handle missing values and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Id                 0\n",
      "MSSubClass         0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "OverallQual        0\n",
      "OverallCond        0\n",
      "YearBuilt          0\n",
      "YearRemodAdd       0\n",
      "MasVnrArea         8\n",
      "BsmtFinSF1         0\n",
      "BsmtFinSF2         0\n",
      "BsmtUnfSF          0\n",
      "TotalBsmtSF        0\n",
      "1stFlrSF           0\n",
      "2ndFlrSF           0\n",
      "LowQualFinSF       0\n",
      "GrLivArea          0\n",
      "BsmtFullBath       0\n",
      "BsmtHalfBath       0\n",
      "FullBath           0\n",
      "HalfBath           0\n",
      "BedroomAbvGr       0\n",
      "KitchenAbvGr       0\n",
      "TotRmsAbvGrd       0\n",
      "Fireplaces         0\n",
      "GarageYrBlt       81\n",
      "GarageCars         0\n",
      "GarageArea         0\n",
      "WoodDeckSF         0\n",
      "OpenPorchSF        0\n",
      "EnclosedPorch      0\n",
      "3SsnPorch          0\n",
      "ScreenPorch        0\n",
      "PoolArea           0\n",
      "MiscVal            0\n",
      "MoSold             0\n",
      "YrSold             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730865</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.229372</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.511418</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.728492</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.451936</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>1.626195</td>\n",
       "      <td>-0.704483</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.489110</td>\n",
       "      <td>-0.614439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.726120</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.093110</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.984752</td>\n",
       "      <td>0.830215</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.092907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631726</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.070361</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>0.990891</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723747</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.456474</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-1.863632</td>\n",
       "      <td>-0.720298</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.176048</td>\n",
       "      <td>4.092524</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>-1.367655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.721374</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.633618</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>1.374795</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>1.364570</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698485</td>\n",
       "      <td>0.780197</td>\n",
       "      <td>0.563760</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.116339</td>\n",
       "      <td>-0.270208</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>2.100892</td>\n",
       "      <td>0.138777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0 -1.730865    0.073375    -0.229372 -0.207142     0.651479    -0.517200   \n",
       "1 -1.728492   -0.872563     0.451936 -0.091886    -0.071836     2.179628   \n",
       "2 -1.726120    0.073375    -0.093110  0.073480     0.651479    -0.517200   \n",
       "3 -1.723747    0.309859    -0.456474 -0.096897     0.651479    -0.517200   \n",
       "4 -1.721374    0.073375     0.633618  0.375148     1.374795    -0.517200   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  GarageArea  \\\n",
       "0   1.050994      0.878668    0.511418    0.575425  ...    0.351000   \n",
       "1   0.156734     -0.429577   -0.574410    1.171992  ...   -0.060731   \n",
       "2   0.984752      0.830215    0.323060    0.092907  ...    0.631726   \n",
       "3  -1.863632     -0.720298   -0.574410   -0.499274  ...    0.790804   \n",
       "4   0.951632      0.733308    1.364570    0.463568  ...    1.698485   \n",
       "\n",
       "   WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "0   -0.752176     0.216503      -0.359325  -0.116339    -0.270208 -0.068692   \n",
       "1    1.626195    -0.704483      -0.359325  -0.116339    -0.270208 -0.068692   \n",
       "2   -0.752176    -0.070361      -0.359325  -0.116339    -0.270208 -0.068692   \n",
       "3   -0.752176    -0.176048       4.092524  -0.116339    -0.270208 -0.068692   \n",
       "4    0.780197     0.563760      -0.359325  -0.116339    -0.270208 -0.068692   \n",
       "\n",
       "    MiscVal    MoSold    YrSold  \n",
       "0 -0.087688 -1.599111  0.138777  \n",
       "1 -0.087688 -0.489110 -0.614439  \n",
       "2 -0.087688  0.990891  0.138777  \n",
       "3 -0.087688 -1.599111 -1.367655  \n",
       "4 -0.087688  2.100892  0.138777  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_openml(name=\"house_prices\", version=1, as_frame=True)\n",
    "X = data.data.select_dtypes(include=[float, int])\n",
    "y = data.target\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(X.isnull().sum())  \n",
    "\n",
    "numeric_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                             ('scaler', StandardScaler())])\n",
    "\n",
    "X_transformed = numeric_pipeline.fit_transform(X)\n",
    "pd.DataFrame(X_transformed, columns=X.columns).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pipeline for Categorical Data Only\n",
    "For a pipeline focused on categorical data only, we can use transformers like SimpleImputer to handle missing values and OneHotEncoder to convert categories into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "sex         0\n",
      "embarked    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_C</th>\n",
       "      <th>x1_Q</th>\n",
       "      <th>x1_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0_female  x0_male  x1_C  x1_Q  x1_S\n",
       "0           1.0      0.0   0.0   0.0   1.0\n",
       "1           0.0      1.0   0.0   0.0   1.0\n",
       "2           1.0      0.0   0.0   0.0   1.0\n",
       "3           0.0      1.0   0.0   0.0   1.0\n",
       "4           1.0      0.0   0.0   0.0   1.0\n",
       "...         ...      ...   ...   ...   ...\n",
       "1304        1.0      0.0   1.0   0.0   0.0\n",
       "1305        1.0      0.0   1.0   0.0   0.0\n",
       "1306        0.0      1.0   1.0   0.0   0.0\n",
       "1307        0.0      1.0   1.0   0.0   0.0\n",
       "1308        0.0      1.0   0.0   0.0   1.0\n",
       "\n",
       "[1309 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_openml(name=\"titanic\", version=1, as_frame=True)\n",
    "X = data.data.select_dtypes(include=\"category\")\n",
    "y = data.target\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "cat_pipeline = Pipeline([('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                         ('encoder', OneHotEncoder())])\n",
    "\n",
    "X_transformed = cat_pipeline.fit_transform(X)\n",
    "pd.DataFrame(data=X_transformed.toarray(), columns=cat_pipeline.named_steps[\"encoder\"].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pipeline for both numerical and categorical features\n",
    "For a dataset with both numerical and categorical features, you can use ColumnTransformer to create separate pipelines for each type and then combine them. This approach is very useful for preprocessing datasets with mixed data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__salary</th>\n",
       "      <th>cat__city_Chicago</th>\n",
       "      <th>cat__city_Houston</th>\n",
       "      <th>cat__city_Los Angeles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.322876</td>\n",
       "      <td>-1.414214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.566947</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.700840</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__salary  cat__city_Chicago  cat__city_Houston  \\\n",
       "0 -1.322876    -1.414214                0.0                0.0   \n",
       "1 -0.566947    -0.707107                0.0                0.0   \n",
       "2  0.188982     0.000000                0.0                0.0   \n",
       "3  0.000000     0.707107                1.0                0.0   \n",
       "4  1.700840     1.414214                0.0                1.0   \n",
       "\n",
       "   cat__city_Los Angeles  \n",
       "0                    1.0  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                    0.0  \n",
       "4                    0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml \n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'age': [20, 25, 30, None, 40],\n",
    "    'salary': [50000, 60000, None, 80000, 90000],\n",
    "    'city': ['Los Angeles', 'Los Angeles', None, 'Chicago', 'Houston']\n",
    "})\n",
    "\n",
    "numerical_cols = ['age','salary']\n",
    "categorical_cols = ['city']\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(missing_values = None, strategy=\"most_frequent\")), \n",
    "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([('num', numeric_pipeline, numerical_cols),\n",
    "                   ('cat', categorical_pipeline, categorical_cols)\n",
    "                   ])\n",
    "processed_data = preprocessor.fit_transform(data)\n",
    "pd.DataFrame(data = processed_data, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Classification Pipeline with Preprocessing\n",
    "\n",
    "A pipeline for a classification model with preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "X,y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X, y, test_size=0.2, shuffle= True, random_state=20)\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Grid Search with a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_depth': 3, 'classifier__min_samples_leaf': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "        'classifier__max_depth': [2,3,5,7],\n",
    "        'classifier__min_samples_leaf':[1,2,3,5]\n",
    "        }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "yhat = grid_search.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_pred=yhat, y_true=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Feature Engineering and Model Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best knn parameters: {'classifier__n_neighbors': 15}\n",
      "accuracy of knn: 0.78\n",
      "best knn parameters: {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 7}\n",
      "accuracy of knn: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = fetch_openml(name=\"titanic\", version=1, as_frame=True)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X = X[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "numerical_cols = ['age', 'fare']\n",
    "categorical_cols = ['pclass', 'sex', 'embarked']\n",
    "pipeline_num = Pipeline([\n",
    "                       ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                       ('scaler', StandardScaler())\n",
    "                     ])\n",
    "\n",
    "pipeline_cat = Pipeline([\n",
    "                       ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                       ('encoder', OneHotEncoder())\n",
    "                     ])\n",
    "preprocessing = ColumnTransformer([\n",
    "                     ('num', pipeline_num, numerical_cols),\n",
    "                     ('cat', pipeline_cat, categorical_cols)\n",
    "                     ])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "                    ('preprocess', preprocessing),\n",
    "                    ('classifier', KNeighborsClassifier())\n",
    "                ])\n",
    "pipeline_tree = Pipeline([\n",
    "                    ('preprocess', preprocessing),\n",
    "                    ('classifier', DecisionTreeClassifier())\n",
    "                ])\n",
    "\n",
    "params_knn = {'classifier__n_neighbors': [3,5,7,11,15,17,31,23,25]}\n",
    "params_tree = {'classifier__max_depth': [2,3,4,5,6,7,8,9,10],\n",
    "               'classifier__min_samples_leaf': [1,2,3,4,5,6,7,8,10]}\n",
    "\n",
    "grid_search_knn = GridSearchCV(pipeline_knn, params_knn, cv=5)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "yhat_knn = grid_search_knn.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"best knn parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"accuracy of knn: {accuracy_score(y_test, yhat_knn):.2f}\")\n",
    "\n",
    "grid_search_tree = GridSearchCV(pipeline_tree, params_tree, cv=5)\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "yhat_tree = grid_search_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"best knn parameters: {grid_search_tree.best_params_}\")\n",
    "print(f\"accuracy of knn: {accuracy_score(y_test, yhat_tree):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
